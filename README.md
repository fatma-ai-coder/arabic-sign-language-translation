# Arabic Sign Language Translation

A computer vision project that translates Arabic sign language gestures into readable text using deep learning techniques.

This project was developed by **Fatma Alamoudi** as part of a research initiative at **Dar Al-Hekma University**, and was presented during the **CCTS 2024 Conference** (Computing and Cybersecurity Technologies Symposium). It aims to contribute to accessible AI solutions for the hearing-impaired community by recognizing Arabic Sign Language (ArSL) letters using a convolutional neural network (CNN).

## 🎯 Project Objectives

- Advance assistive technology for Arabic-speaking individuals with hearing impairments.
- Build a reliable machine learning model capable of recognizing static ArSL hand gestures.
- Present and document the work as a formal research contribution.


## 📚 Dataset

- [KARSL-502 Arabic Sign Language Dataset](https://www.kaggle.com/datasets/yousefdotpy/karsl-502)

## 🧪 Tools and Technologies

- Python  
- TensorFlow / Keras  
- OpenCV  
- NumPy, Pandas  
- Matplotlib

## 📄 Research Paper

Full details of the methodology, experimentation process, and results are available in the paper below:

📘 [View the paper (PDF)](docs/arabic_sign_language_paper.pdf)

## 🌱 Future Directions

- Extend model to support full-word and sentence-level sign recognition.
- Apply time-series models for dynamic gestures.
- Build a real-time application for deployment in educational or assistive tools.
- Explore larger datasets and transfer learning approaches.

## 🙏 Acknowledgments

The initial concept and base code were adapted from [Pavly Halim](https://github.com/pavlyhalim/Arabic-Sign-Language) under the MIT License.  
This version was **significantly restructured and extended** by **Fatma Alamoudi** for academic research and presentation at **CCTS 2023**.

## 📜 License

This repository is licensed under the [MIT License](LICENSE).
