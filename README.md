# arabic-sign-language-translation

A project that translates Arabic sign language gestures into text using computer vision and machine learning.

This project aims to recognize Arabic Sign Language letters from images using computer vision and deep learning techniques. It leverages a Convolutional Neural Network (CNN) trained on a publicly available dataset and serves as a step toward developing assistive technologies for the hearing-impaired community.

## Overview

- Implemented a CNN model to classify Arabic sign language gestures.
- Utilized the KARSL-502 dataset from Kaggle for training and validation.
- Adapted and extended an open-source project initially developed by [Pavly Halim](https://github.com/pavlyhalim/Arabic-Sign-Language).
- Further modifications and structuring were done by Fatima Alamoudi for research exploration.

## Dataset

- [KARSL-502 Arabic Sign Language Dataset](https://www.kaggle.com/datasets/yousefdotpy/karsl-502)

## Tools and Technologies

- Python
- TensorFlow / Keras
- OpenCV
- NumPy, Pandas
- Matplotlib

## Future Improvements

- Improve model performance through hyperparameter tuning and augmentation.
- Expand to sentence-level recognition.
- Deploy the system as a simple web or desktop application for accessibility testing.

## Credits

This project was originally developed by [Pavly Halim](https://github.com/pavlyhalim/Arabic-Sign-Language) under the MIT License.  
The current version includes adaptations and restructuring by Fatima Alamoudi as part of academic research on accessible AI applications.

## License

This repository follows the [MIT License](LICENSE).
